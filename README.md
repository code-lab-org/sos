# SOS <!-- omit from toc -->

This repository contains the codebase for Snow Observing Strategy (SOS) applications integrated within the [Novel Observing Strategies Testbed (NOS-T)](https://github.com/code-lab-org/nost-tools).

- [Installation](#installation)
  - [NOS-T Tools Installation](#nos-t-tools-installation)
  - [AWS CLI Installation](#aws-cli-installation)
- [Introduction](#introduction)
  - [Applications Overview](#applications-overview)
  - [Messaging Protocol](#messaging-protocol)
  - [Data Structure \& Interfaces](#data-structure--interfaces)
- [Execution](#execution)
  - [Conda](#conda)
  - [Docker](#docker)


## Installation

### NOS-T Tools Installation

To install the NOS-T library, follow the directions [here](https://nost-tools-v2.readthedocs.io/en/latest/installation/installation.html).

### AWS CLI Installation

To setup the Amazon Web Services (AWS) command line interface (CLI), follow the directions [here](https://nost-tools-v2.readthedocs.io/en/latest/operators_guide/modules/aws.html).

## Introduction

A single manager application is responsible for orchestrating the various applications and keeping a consistent time across applications. Upon initiation of the manager, various managed applications are triggered, each responsible for generating derived, merged datasets or raster layers sent as base64-encoded strings. Below is a table describing each application:

|Application|Purpose|Data Source|Developed|Containerized|
|:---------:|:-----:|:---------:|:-------:|:-----------:|
|**Manager**|Orchestrates applications, maintains time|NA|Y|Y|
|**Planner**|Selects best taskable observations on the basis of reward|LIS|Y|N|
|**Appender**|Aggregates planned taskable observations, filtering duplicates|Planner|Y|N|
|**Simulator**|Simulates satellite operations and determines when and where observations are collected|Appender|Y|N|

### Applications Overview

Applications communicate via a RabbitMQ message broker utilizing the Advanced Message Queuing Protocol (AMQP) protocol. The figure below illustrates the overall workflow:

<p align="center">
  <img src="https://pointillism.io/code-lab-org/sos/blob/main/docs/workflow.dot.svg"/>
  <br>
  <em>Snow Observing Systems (SOS) application workflow.</em>
</p>

### Messaging Protocol

The SOS applications utilize the [Advanced Message Queuing Protocol (AMQP)](https://www.amqp.org/) through a [RabbitMQ event broker](http://rabbitmq.com/). These messages include:

| Application | Receives | Sends |
|:-----------:|:--------:|:-----:|
| **Planner** | Data availability messages from AWS Lambda function | Selected cells are saved as GeoJSON file and the contents of this file are also sent as an AMQP message to the appender application |
| **Appender** | Message from planner containing the selected cells | Aggregates the selected cells into a record, filters duplicate rows, and sends an AMQP message to the simulator application |
| **Simulator** | Message from the appender containing the aggregated selected cells record | Simulate satellite operations and determines when and where observations are collected, sends to Cesium web application |

### Data Structure & Interfaces

The input data and output data generated by applications are uploaded onto an Amazon Web Services (AWS) Simple Storage Service (S3) bucket.

> **Note:** The applications use the AWS SDK for Python, [Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html). Boto3 allows users to create, configure, and manage AWS services, including S3, Simple Notification Service (SNS), and Elastic Compute Cloud (EC2). Access to the AWS SDK is limited to SOS administrators as required by NASA's [Science Managed Cloud Environment (SMCE)](https://smce.nasa.gov/). 

<p align="center">
  <img src="https://pointillism.io/code-lab-org/sos/blob/main/docs/aws.dot.svg"/>
  <br>
  <em>Amazon Web Services (AWS) resources used by the SOS applications within the NOS-T system include S3 and Lambda.</em>
</p>

The LIS inputs are stored in an S3 bucket, which the SOS applications access. The SOS applications then output data into an output directory, organized by the specific day and application. Below is an example:

```bash
snow_observing_systems/
├── input
│   ├── 2019-03-01
│   │   └── LIS
│   ├── 2019-03-02
│   │   └── LIS
│   └── 2019-03-03
│       └── LIS
└── output
    ├── 2019-03-01
    │   ├── Appender
    │   ├── Planner
    │   └── Simulator
    ├── 2019-03-02
    │   ├── Appender
    │   ├── Planner
    │   └── Simulator
    └── 2019-03-03
        ├── Appender
        ├── Planner
        └── Simulator
```

<p align="center">
  <img src="https://pointillism.io/code-lab-org/sos/blob/main/docs/apps.dot.svg"/>
  <br>
  <em>Flow of data between the various applications.</em>
</p>

## Execution

The SOS applications can be executed using Conda or Docker. The steps for executing Conda are provided below, assuming you have following the [NOS-T installation instructions](https://nost-tools-v2.readthedocs.io/en/latest/installation/installation.html) and [AWS CLI installation instructions](https://nost-tools-v2.readthedocs.io/en/latest/operators_guide/modules/aws.html).

### Conda

Activate the Conda environment:

```bash
conda activate nost
```

Run each application in a separate terminal, making sure to start the manager application first:

- Terminal 1:

```bash
python3 src/manager/main.py
```

- Terminal 2:

```bash
python3 src/planner/main.py
```

- Terminal 3:

```bash
python3 src/appender/main.py
```

- Terminal 4:
```bash
python3 src/simulator/main.py
```

Below is an example:

<p align="center">
  <img src="./docs/terminal.png"/>
  <br>
  <em>Terminal running all four SOS applications.</em>
</p>

### Docker

> **Note:** This section is coming soon.

<!-- ### Docker (Development)

Each container can be built individually during development, to build a local version of a container, you can use ```docker build```. 

For example, to build the "manager" comntainer:

```
cd src/manager/
docker build -t sos_manager .
docker run --rm --env-file .env -v "$(pwd)/data":/opt/data sos_manager
```

> NOTE: You can follow similar steps to build the other containers, such as satellites, layer_resolution, layer_snow_cover, etc.

### Docker Compose
Three applications, including manager, satellite, and snow cover layer applications, can be run using Docker compose. To run applications, do the following:

1. Download input data, which should be in the following structure:

    ```
    data/
    ├── Downloaded_files
    │   ├── Mo_basin_shp
    │   │   ├── WBD_10_HU2_Shape
    │   │   └── WBD_10_HU2_Shape.zip
    │   ├── Resolution_raw
    │   │   └── SNODAS
    │   └── Snow_cover_raw
    │       ├── hdf
    │       └── nc
    ├── Efficiency_files
    │   ├── Efficiency_high_resolution_Caesium
    │   │   ├── efficiency_resolution.nc
    │   │   ├── efficiency_resolution_taskable.nc
    │   │   ├── efficiency_snow_cover.nc
    │   │   └── efficiency_snow_cover_up.nc
    │   └── Efficiency_resolution20_Optimization
    │       ├── Efficiency_SWE_Change_dataset_Capella.nc
    │       ├── Efficiency_Sensor_dataset.nc
    │       ├── Efficiency_Sensor_dataset_Capella.nc
    │       ├── Efficiency_Sensor_dataset_GCOM.nc
    │       ├── Efficiency_Temperature_dataset.nc
    │       ├── Efficiency_Temperature_dataset_coarsened.nc
    │       ├── Optimization_result.geojson
    │       ├── Temperature_dataset.nc
    │       ├── coarsened_eta_output_Capella.nc
    │       ├── coarsened_eta_output_GCOM.nc
    │       ├── efficiency_resolution_layer.nc
    │       ├── efficiency_snow_cover.nc
    │       ├── eta0_resampled_to_match_coarsened_grid.nc
    │       ├── final_blocks_rewards.geojson
    │       ├── final_eta_combined_output_Capella.nc
    │       └── final_eta_combined_output_GCOM.nc
    └── Preprocessed_files
        ├── preprocessed_resolution.nc
        └── preprocessed_snow_cover.nc
    ```

1. Confirm you have a .env file in your working directory with the following contents:

    ```
    # FILE/DIR PATHS 
    path_hdf=data/Downloaded_files/Snow_cover_raw/hdf
    path_nc=data/Downloaded_files/Snow_cover_raw/nc/
    path_shp=data/Downloaded_files/Mo_basin_shp/
    path_preprocessed=data/Preprocessed_files/
    path_efficiency=data/Efficiency_files/Efficiency_high_resolution_Caesium/
    raw_path=data/Downloaded_files/Resolution_raw/

    # EARTHACCESS LOGIN
    EARTHDATA_USERNAME=<Your EarthAccess username>
    EARTHDATA_PASSWORD=<Your EarthAccess password>

    # NOS-T LOGIN
    HOST=<Contact NOS-T admins>
    KEYCLOAK_PORT=8443
    KEYCLOAK_REALM=<Contact NOS-T admins>
    RABBITMQ_PORT=5671
    USERNAME=<Your Keycloak username in NOS-T ecosystem>
    PASSWORD=<Your Keycloak password in NOS-T ecosystem>
    CLIENT_ID=<Contact NOS-T admins>
    CLIENT_SECRET_KEY=<Contact NOS-T admins>
    VIRTUAL_HOST="/"
    IS_TLS=True

    # CESIUM LOGIN
    TOKEN=<Cesium access token>
    ```

1. Orchestrate the containers:

    ```
    docker-compose up -d
    ```

    > NOTE: To confirm Docker containers are running, run the command: ```docker ps```. You should see three containers list: sos_manager, sos_satellites, and sos_snow_cover_layer.

1. To shutdown the Docker containers:

    ```
    docker-compose down
    ``` -->